inspect(docs[1])
inspect(docs[2])
for(j in seq(docs))
{
docs[[j]] <- gsub("/", " ", docs[[j]])
docs[[j]] <- gsub("@", " ", docs[[j]])
docs[[j]] <- gsub("\\|", " ", docs[[j]])
}
inspect(docs[1])
inspect(docs[1])
# stopwords("english")
docs <- tm_map(docs, removeWords, stopwords("english"))
inspect(docs[3])
docs <- tm_map(docs, removeWords, c("department", "email"))
inspect(docs[3])
docs <- tm_map(docs, removeWords, c("department", "email"))
for (j in seq(docs))
{
docs[[j]] <- gsub("qualitative research", "QDA", docs[[j]])
docs[[j]] <- gsub("qualitative studies", "QDA", docs[[j]])
docs[[j]] <- gsub("qualitative analysis", "QDA", docs[[j]])
docs[[j]] <- gsub("research methods", "research_methods", docs[[j]])
}
library(SnowballC)
docs <- tm_map(docs, stemDocument)
inspect(docs[1])
docs <- tm_map(docs, stripWhitespace)
inspect(docs[3])
docs <- tm_map(docs, PlainTextDocument)
inspect(docs[3])
dtm <- DocumentTermMatrix(docs)
dtm
inspect(dtm)
inspect(dtm[1:5, 1:20])
dim(dtm)
tdm <- TermDocumentMatrix(docs)
tdm
freq <- colSums(as.matrix(dtm))
length(freq)
ord <- order(freq)
m <- as.matrix(dtm)
dim(m)
dtms <- removeSparseTerms(dtm, 0.1) # This makes a matrix that is 10% empty space, maximum.
inspect(dtms)
freq[head(ord)]
freq[tail(ord)]
head(table(freq), 20)
tail(table(freq), 20)
freq <- colSums(as.matrix(dtms))
freq
freq <- sort(colSums(as.matrix(dtm)), decreasing=TRUE)
head(freq, 14)
findFreqTerms(dtm, lowfreq=50)
wf <- data.frame(word=names(freq), freq=freq)
head(wf)
library(ggplot2)
p <- ggplot(subset(wf, freq>50), aes(word, freq))
p <- p + geom_bar(stat="identity")
p <- p + theme(axis.text.x=element_text(angle=45, hjust=1))
p
install.packages("plotly")
devtools::install_github("ropensci/plotly")
Sys.setenv("plotly_username"="CrystalYan")
Sys.setenv("plotly_api_key"="sNwtTsyAC3C1no0w4xZl")
install.packages("plotly")
library(plotly)
plotly_POST(p, filename = "word cloud")
findAssocs(dtm, c("question" , "analysi"), corlimit=0.98)
findAssocs(dtms, "contrast", corlimit=0.90)
library(wordcloud)
set.seed(142)
wordcloud(names(freq), freq, min.freq=25)
set.seed(142)
wordcloud(names(freq), freq, max.words=100)
set.seed(142)
wordcloud(names(freq), freq, min.freq=20, scale=c(5, .1), colors=brewer.pal(6, "Dark2"))
set.seed(142)
dark2 <- brewer.pal(6, "Dark2")
wordcloud(names(freq), freq, max.words=100, rot.per=0.2, colors=dark2)
dtmss <- removeSparseTerms(dtm, 0.15) # This makes a matrix that is only 15% empty space, maximum.
inspect(dtmss)
library(cluster)
d <- dist(t(dtmss), method="euclidian")
fit <- hclust(d=d, method="ward")
fit
library(cluster)
d <- dist(t(dtmss), method="euclidian")
fit <- hclust(d=d, method="ward.D")
fit
dtmss <- removeSparseTerms(dtm, 0.15) # This makes a matrix that is only 15% empty space, maximum.
inspect(dtmss)
library(cluster)
d <- dist(t(dtmss), method="euclidian")
fit <- hclust(d=d, method="ward.D")
fit
library(cluster)
d <- dist(t(dtmss), method="euclidian")
fit <- hclust(d=d, method="ward.D")
library(cluster)
d <- dist(t(dtmss), method="euclidian")
fit <- hclust(d=d, method="ward.D")
fit
dtmss <- removeSparseTerms(dtm, 0.15) # This makes a matrix that is only 15% empty space, maximum.
inspect(dtmss)
library(cluster)
d <- dist(t(dtmss), method="euclidian")
fit <- hclust(d=d, method="ward.D")
fit
library(wordcloud)
set.seed(142)
wordcloud(names(freq), freq, min.freq=25)
d <- dist(t(dtms), method="euclidian")
fit <- hclust(d=d, method="ward.D")
fit <- hclust(d=d, method="ward")
d <- dist(t(dtmss), method="euclidian")
fit <- hclust(d=d, method="ward")
library(fpc)
d <- dist(t(dtmss), method="euclidian")
kfit <- kmeans(d, 2)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
library(cluster)
d <- dist(t(dtmss), method="euclidian")
fit <- hclust(d=d, method="ward")
fit
plot(fit, hang=-1)
plot.new()
plot(fit, hang=-1)
groups <- cutree(fit, k=5) # "k=" defines the number of clusters you are using
rect.hclust(fit, k=5, border="red")
library(fpc)
d <- dist(t(dtmss), method="euclidian")
kfit <- kmeans(d, 2)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
library(fpc)
d <- dist(t(dtmss), method="euclidian")
kfit <- kmeans(d, 2)
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
library(fpc)
d <- dist(t(dtmss), method="euclidian")
kfit <- kmeans(d, 2)
cname <- file.path("C:","odyssey")
cname
setwd("C:/Users/kein/Desktop/FinalProjectBigData/resource/LyricsMining1.0")
devtools::install_github("mjockers/syuzhet")
install.packages("textcat")
library(ggplot2)
library(tm)
library(wordcloud)
library(syuzhet)
library(SnowballC)
library(textcat)
texts <-file("song_labels_A.txt","r")##texts is the whole file
outfile <- file("result_4.5.txt", "w")
line<-readLines(texts,n=1)
##paste(line)
while( length(line) != 0) {
line1 <- strsplit(line,",")
LyricsLine <- line1[[1]][3]##find the lyrics part
ArtistLine <- line1[[1]][1]
SongNameLine <- line1[[1]][2]
if((!is.na(textcat(LyricsLine)))&&(textcat(LyricsLine) == 'english')&&(length(LyricsLine)>=1)){
##print(LyricsLine)
docs <- Corpus(VectorSource(LyricsLine))##read the text
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, tolower)
docs <- tm_map(docs, removeWords, stopwords("english"))
## docs <- tm_map(docs, removeWords, c("black", "bones"))
docs <- tm_map(docs, stemDocument)
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, PlainTextDocument)
######build TDM
dtm <- TermDocumentMatrix(docs)
mat <- as.matrix(dtm)
v <- sort(rowSums(mat),decreasing = TRUE)
d <- data.frame(word = names(v),freq = v)
##head (d,10)##get top 10 frequent words
topWords <- as.character(head(d,10)$word)##get the first row
#
#paste0(topWords)
##while(length(topWords)>1){
Sentiment <- get_nrc_sentiment(LyricsLine)
text <- cbind(LyricsLine,Sentiment)
TotalSentiment <- data.frame(colSums(text[,c(2:11)]))
names(TotalSentiment) <- "count"
TotalSentiment <- cbind("sentiment" = rownames(TotalSentiment),TotalSentiment)
rownames(TotalSentiment) <- NULL
##ggplot(data = TotalSentiment, aes(x = sentiment, y = count))+
##geom_bar(aes(fill = sentiment), stat = "identity")+
##theme(legend.position = "none") +
##xlab("Sentiment") + ylab("Total Count") + ggtitle("Total Sentiment Score")
sentiText <- text[,c(2:11)]
DescSentiment <- TotalSentiment[order(TotalSentiment[,2],decreasing=T),]
topSentiment <- head(DescSentiment,5)[,1]
##print(topSentiment)
##score
totolScore <- sentiText[,1]+sentiText[,2]+sentiText[,3]+sentiText[,4]+sentiText[,5]+sentiText[,6]+sentiText[,7]+sentiText[,8]+sentiText[,9]+sentiText[,10]
positiveScore <- sentiText[,2]+sentiText[,5]+sentiText[,7]+sentiText[,8]+sentiText[,10]
SentiScore<- floor((positiveScore/totolScore*10))
joySentiment <- sentiText[,2]+sentiText[,5]+sentiText[,7]+sentiText[,8]
joyScore<-  floor(joySentiment/totolScore*10)
sorrowSentiment <- sentiText[,6]+sentiText[,4]
sorrowScore<-  floor(sorrowSentiment/totolScore*10)
surpriseScore <-  floor(sentiText[,7]/totolScore*10)
angryScore <-  floor(sentiText[,1]/totolScore*10)
######
totalResult <- c(paste0(ArtistLine),sep=",",paste0(SongNameLine),sep=",",
SentiScore,sep=",",
joyScore,sep=",",sorrowScore,sep=",",angryScore,sep=",",surpriseScore,sep=",",
paste0(topWords),sep="\n")
##paste0(totalResult)
##write.table(paste(totalResult, sep=" ", collapse=", "), "/Users/kein/Desktop/tryResult/Rdata1.txt", sep="\t")
cat(totalResult,file=outfile)
line<-readLines(texts,n=1)
}else{
line<-readLines(texts,n=1)
}
}
print("done")
devtools::install_github("mjockers/syuzhet")
install.packages("textcat")
library(ggplot2)
library(tm)
library(wordcloud)
library(syuzhet)
library(SnowballC)
library(textcat)
texts <-file("song_labels_E.txt","r")##texts is the whole file
outfile <- file("result_4.6.txt", "w")
line<-readLines(texts,n=1)
##paste(line)
while( length(line) != 0) {
line1 <- strsplit(line,",")
LyricsLine <- line1[[1]][3]##find the lyrics part
ArtistLine <- line1[[1]][1]
SongNameLine <- line1[[1]][2]
if((!is.na(textcat(LyricsLine)))&&(textcat(LyricsLine) == 'english')&&(length(LyricsLine)>=1)){
##print(LyricsLine)
docs <- Corpus(VectorSource(LyricsLine))##read the text
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, tolower)
docs <- tm_map(docs, removeWords, stopwords("english"))
## docs <- tm_map(docs, removeWords, c("black", "bones"))
docs <- tm_map(docs, stemDocument)
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, PlainTextDocument)
######build TDM
dtm <- TermDocumentMatrix(docs)
mat <- as.matrix(dtm)
v <- sort(rowSums(mat),decreasing = TRUE)
d <- data.frame(word = names(v),freq = v)
##head (d,10)##get top 10 frequent words
topWords <- as.character(head(d,10)$word)##get the first row
#
#paste0(topWords)
##while(length(topWords)>1){
Sentiment <- get_nrc_sentiment(LyricsLine)
text <- cbind(LyricsLine,Sentiment)
TotalSentiment <- data.frame(colSums(text[,c(2:11)]))
names(TotalSentiment) <- "count"
TotalSentiment <- cbind("sentiment" = rownames(TotalSentiment),TotalSentiment)
rownames(TotalSentiment) <- NULL
##ggplot(data = TotalSentiment, aes(x = sentiment, y = count))+
##geom_bar(aes(fill = sentiment), stat = "identity")+
##theme(legend.position = "none") +
##xlab("Sentiment") + ylab("Total Count") + ggtitle("Total Sentiment Score")
sentiText <- text[,c(2:11)]
DescSentiment <- TotalSentiment[order(TotalSentiment[,2],decreasing=T),]
topSentiment <- head(DescSentiment,5)[,1]
##print(topSentiment)
##score
totolScore <- sentiText[,1]+sentiText[,2]+sentiText[,3]+sentiText[,4]+sentiText[,5]+sentiText[,6]+sentiText[,7]+sentiText[,8]+sentiText[,9]+sentiText[,10]
positiveScore <- sentiText[,2]+sentiText[,5]+sentiText[,7]+sentiText[,8]+sentiText[,10]
SentiScore<- floor((positiveScore/totolScore*10))
joySentiment <- sentiText[,2]+sentiText[,5]+sentiText[,7]+sentiText[,8]
joyScore<-  floor(joySentiment/totolScore*10)
sorrowSentiment <- sentiText[,6]+sentiText[,4]
sorrowScore<-  floor(sorrowSentiment/totolScore*10)
surpriseScore <-  floor(sentiText[,7]/totolScore*10)
angryScore <-  floor(sentiText[,1]/totolScore*10)
######
totalResult <- c(paste0(ArtistLine),sep=",",paste0(SongNameLine),sep=",",
SentiScore,sep=",",
joyScore,sep=",",sorrowScore,sep=",",angryScore,sep=",",surpriseScore,sep=",",
paste0(topWords),sep="\n")
##paste0(totalResult)
##write.table(paste(totalResult, sep=" ", collapse=", "), "/Users/kein/Desktop/tryResult/Rdata1.txt", sep="\t")
cat(totalResult,file=outfile)
line<-readLines(texts,n=1)
}else{
line<-readLines(texts,n=1)
}
}
texts <-file("song_labels_E.txt","r")##texts is the whole file
outfile <- file("result_4.6.txt", "w")
line<-readLines(texts,n=1)
##paste(line)
while( length(line) != 0) {
line1 <- strsplit(line,",")
LyricsLine <- line1[[1]][3]##find the lyrics part
ArtistLine <- line1[[1]][1]
SongNameLine <- line1[[1]][2]
if((!is.na(textcat(LyricsLine)))&&(textcat(LyricsLine) == 'english')&&(length(LyricsLine)>=1)){
##print(LyricsLine)
docs <- Corpus(VectorSource(LyricsLine))##read the text
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, tolower)
docs <- tm_map(docs, removeWords, stopwords("english"))
## docs <- tm_map(docs, removeWords, c("black", "bones"))
docs <- tm_map(docs, stemDocument)
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, PlainTextDocument)
######build TDM
dtm <- TermDocumentMatrix(docs)
mat <- as.matrix(dtm)
v <- sort(rowSums(mat),decreasing = TRUE)
d <- data.frame(word = names(v),freq = v)
##head (d,10)##get top 10 frequent words
topWords <- as.character(head(d,10)$word)##get the first row
#
#paste0(topWords)
##while(length(topWords)>1){
Sentiment <- get_nrc_sentiment(LyricsLine)
text <- cbind(LyricsLine,Sentiment)
TotalSentiment <- data.frame(colSums(text[,c(2:11)]))
names(TotalSentiment) <- "count"
TotalSentiment <- cbind("sentiment" = rownames(TotalSentiment),TotalSentiment)
rownames(TotalSentiment) <- NULL
##ggplot(data = TotalSentiment, aes(x = sentiment, y = count))+
##geom_bar(aes(fill = sentiment), stat = "identity")+
##theme(legend.position = "none") +
##xlab("Sentiment") + ylab("Total Count") + ggtitle("Total Sentiment Score")
sentiText <- text[,c(2:11)]
DescSentiment <- TotalSentiment[order(TotalSentiment[,2],decreasing=T),]
topSentiment <- head(DescSentiment,5)[,1]
##print(topSentiment)
##score
totolScore <- sentiText[,1]+sentiText[,2]+sentiText[,3]+sentiText[,4]+sentiText[,5]+sentiText[,6]+sentiText[,7]+sentiText[,8]+sentiText[,9]+sentiText[,10]
positiveScore <- sentiText[,2]+sentiText[,5]+sentiText[,7]+sentiText[,8]+sentiText[,10]
SentiScore<- floor((positiveScore/totolScore*10))
joySentiment <- sentiText[,2]+sentiText[,5]+sentiText[,7]+sentiText[,8]
joyScore<-  floor(joySentiment/totolScore*10)
sorrowSentiment <- sentiText[,6]+sentiText[,4]
sorrowScore<-  floor(sorrowSentiment/totolScore*10)
surpriseScore <-  floor(sentiText[,7]/totolScore*10)
angryScore <-  floor(sentiText[,1]/totolScore*10)
######
totalResult <- c(paste0(ArtistLine),sep=",",paste0(SongNameLine),sep=",",
SentiScore,sep=",",
joyScore,sep=",",sorrowScore,sep=",",angryScore,sep=",",surpriseScore,sep=",",
paste0(topWords),sep="\n")
##paste0(totalResult)
##write.table(paste(totalResult, sep=" ", collapse=", "), "/Users/kein/Desktop/tryResult/Rdata1.txt", sep="\t")
cat(totalResult,file=outfile)
line<-readLines(texts,n=1)
}else{
line<-readLines(texts,n=1)
}
}
print("done")
library(ggplot2)
library(tm)
library(wordcloud)
library(syuzhet)
library(SnowballC)
library(textcat)
texts <-file("song_labels_E.txt","r")##texts is the whole file
outfile <- file("result_4.6.txt", "w")
line<-readLines(texts,n=1)
##paste(line)
while( length(line) != 0) {
line1 <- strsplit(line,",")
LyricsLine <- line1[[1]][3]##find the lyrics part
ArtistLine <- line1[[1]][1]
SongNameLine <- line1[[1]][2]
if((!is.na(textcat(LyricsLine)))&&(textcat(LyricsLine) == 'english')&&(length(LyricsLine)>=1)){
##print(LyricsLine)
docs <- Corpus(VectorSource(LyricsLine))##read the text
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, tolower)
docs <- tm_map(docs, removeWords, stopwords("english"))
## docs <- tm_map(docs, removeWords, c("black", "bones"))
docs <- tm_map(docs, stemDocument)
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, PlainTextDocument)
######build TDM
dtm <- TermDocumentMatrix(docs)
mat <- as.matrix(dtm)
v <- sort(rowSums(mat),decreasing = TRUE)
d <- data.frame(word = names(v),freq = v)
##head (d,10)##get top 10 frequent words
topWords <- as.character(head(d,10)$word)##get the first row
#
#paste0(topWords)
##while(length(topWords)>1){
Sentiment <- get_nrc_sentiment(LyricsLine)
text <- cbind(LyricsLine,Sentiment)
TotalSentiment <- data.frame(colSums(text[,c(2:11)]))
names(TotalSentiment) <- "count"
TotalSentiment <- cbind("sentiment" = rownames(TotalSentiment),TotalSentiment)
rownames(TotalSentiment) <- NULL
##ggplot(data = TotalSentiment, aes(x = sentiment, y = count))+
##geom_bar(aes(fill = sentiment), stat = "identity")+
##theme(legend.position = "none") +
##xlab("Sentiment") + ylab("Total Count") + ggtitle("Total Sentiment Score")
sentiText <- text[,c(2:11)]
DescSentiment <- TotalSentiment[order(TotalSentiment[,2],decreasing=T),]
topSentiment <- head(DescSentiment,5)[,1]
##print(topSentiment)
##score
totolScore <- sentiText[,1]+sentiText[,2]+sentiText[,3]+sentiText[,4]+sentiText[,5]+sentiText[,6]+sentiText[,7]+sentiText[,8]+sentiText[,9]+sentiText[,10]
positiveScore <- sentiText[,2]+sentiText[,5]+sentiText[,7]+sentiText[,8]+sentiText[,10]
SentiScore<- floor((positiveScore/totolScore*10))
joySentiment <- sentiText[,2]+sentiText[,5]+sentiText[,7]+sentiText[,8]
joyScore<-  floor(joySentiment/totolScore*10)
sorrowSentiment <- sentiText[,6]+sentiText[,4]
sorrowScore<-  floor(sorrowSentiment/totolScore*10)
surpriseScore <-  floor(sentiText[,7]/totolScore*10)
angryScore <-  floor(sentiText[,1]/totolScore*10)
######
totalResult <- c(paste0(ArtistLine),sep=",",paste0(SongNameLine),sep=",",
SentiScore,sep=",",
joyScore,sep=",",sorrowScore,sep=",",angryScore,sep=",",surpriseScore,sep=",",
paste0(topWords),sep="\n")
##paste0(totalResult)
##write.table(paste(totalResult, sep=" ", collapse=", "), "/Users/kein/Desktop/tryResult/Rdata1.txt", sep="\t")
cat(totalResult,file=outfile)
line<-readLines(texts,n=1)
}else{
line<-readLines(texts,n=1)
}
}
print("done")
devtools::install_github("mjockers/syuzhet")
install.packages("textcat")
library(ggplot2)
library(tm)
library(wordcloud)
library(syuzhet)
library(SnowballC)
library(textcat)
texts <-file("try1.txt","r")##texts is the whole file
outfile <- file("result_4.7.txt", "w")
line<-readLines(texts,n=1)
##paste(line)
while( length(line) != 0) {
line1 <- strsplit(line,",")
LyricsLine <- line1[[1]][3]##find the lyrics part
ArtistLine <- line1[[1]][1]
SongNameLine <- line1[[1]][2]
if((!is.na(textcat(LyricsLine)))&&(textcat(LyricsLine) == 'english')&&(length(LyricsLine)>=1)){
##print(LyricsLine)
docs <- Corpus(VectorSource(LyricsLine))##read the text
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, tolower)
docs <- tm_map(docs, removeWords, stopwords("english"))
## docs <- tm_map(docs, removeWords, c("black", "bones"))
docs <- tm_map(docs, stemDocument)
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, PlainTextDocument)
######build TDM
dtm <- TermDocumentMatrix(docs)
mat <- as.matrix(dtm)
v <- sort(rowSums(mat),decreasing = TRUE)
d <- data.frame(word = names(v),freq = v)
##head (d,10)##get top 10 frequent words
topWords <- as.character(head(d,10)$word)##get the first row
#
#paste0(topWords)
##while(length(topWords)>1){
Sentiment <- get_nrc_sentiment(LyricsLine)
text <- cbind(LyricsLine,Sentiment)
TotalSentiment <- data.frame(colSums(text[,c(2:11)]))
names(TotalSentiment) <- "count"
TotalSentiment <- cbind("sentiment" = rownames(TotalSentiment),TotalSentiment)
rownames(TotalSentiment) <- NULL
##ggplot(data = TotalSentiment, aes(x = sentiment, y = count))+
##geom_bar(aes(fill = sentiment), stat = "identity")+
##theme(legend.position = "none") +
##xlab("Sentiment") + ylab("Total Count") + ggtitle("Total Sentiment Score")
sentiText <- text[,c(2:11)]
DescSentiment <- TotalSentiment[order(TotalSentiment[,2],decreasing=T),]
topSentiment <- head(DescSentiment,5)[,1]
##print(topSentiment)
##score
totolScore <- sentiText[,1]+sentiText[,2]+sentiText[,3]+sentiText[,4]+sentiText[,5]+sentiText[,6]+sentiText[,7]+sentiText[,8]+sentiText[,9]+sentiText[,10]
positiveScore <- sentiText[,2]+sentiText[,5]+sentiText[,7]+sentiText[,8]+sentiText[,10]
SentiScore<- floor((positiveScore/totolScore*10))
joySentiment <- sentiText[,2]+sentiText[,5]+sentiText[,7]+sentiText[,8]
joyScore<-  floor(joySentiment/totolScore*10)
sorrowSentiment <- sentiText[,6]+sentiText[,4]
sorrowScore<-  floor(sorrowSentiment/totolScore*10)
surpriseScore <-  floor(sentiText[,7]/totolScore*10)
angryScore <-  floor(sentiText[,1]/totolScore*10)
######
totalResult <- c(paste0(ArtistLine),sep=",",paste0(SongNameLine),sep=",",
SentiScore,sep=",",
joyScore,sep=",",sorrowScore,sep=",",angryScore,sep=",",surpriseScore,sep=",",
paste0(topWords),sep="\n")
##paste0(totalResult)
##write.table(paste(totalResult, sep=" ", collapse=", "), "/Users/kein/Desktop/tryResult/Rdata1.txt", sep="\t")
cat(totalResult,file=outfile)
line<-readLines(texts,n=1)
}else{
line<-readLines(texts,n=1)
}
}
print("done")
